{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc03890e",
   "metadata": {},
   "source": [
    "### Part c (Dropout Regularization)\n",
    "\n",
    "#### Introduction\n",
    "I implemented a dropout layer in PyTorch using 'nn.dropout'. I found that a lower dropout rate was better, as this is probably because the network is on the smaller size and overfitting is less of a concern. \n",
    "\n",
    "#### Results\n",
    "As you can see below, I achieved a L2-Relative error of 0.045 < 0.05, after using 100,000 epochs, a learning rate of 0.001, and a dropout rate of 0.02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0418d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the oscillatory function\n",
    "def f(x):\n",
    "    result = torch.zeros_like(x)\n",
    "    result[x < 0] = 5 + sum(torch.sin(k * x[x < 0]) for k in range(1, 5))\n",
    "    result[x >= 0] = torch.cos(10 * x[x >= 0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1e2f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data\n",
    "x_train = torch.linspace(-np.pi, np.pi, 80)\n",
    "y_train = f(x_train) + torch.randn(x_train.size()) * 0.1  # Adding Gaussian noise\n",
    "\n",
    "# Generate testing data\n",
    "x_test = torch.linspace(-np.pi, np.pi, 1000)\n",
    "y_test = f(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5f5c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network with dropout\n",
    "class ReLUNetWithDropout(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(ReLUNetWithDropout, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 50)  # Input layer to hidden layer with 50 neurons\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)  # Dropout layer after the first hidden layer\n",
    "        self.fc2 = nn.Linear(50, 50)  # Hidden layer to another hidden layer with 50 neurons\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)  # Dropout layer after the second hidden layer\n",
    "        self.fc3 = nn.Linear(50, 1)  # Hidden layer to output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x.unsqueeze(1)))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da29a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, loss function, and optimizer\n",
    "dropout_rate = 0.02\n",
    "model = ReLUNetWithDropout(dropout_rate=dropout_rate)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb0ec113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 8.863788604736328\n",
      "Epoch 500, Loss: 0.504927933216095\n",
      "Epoch 1000, Loss: 0.34009379148483276\n",
      "Epoch 1500, Loss: 0.27647072076797485\n",
      "Epoch 2000, Loss: 0.22000804543495178\n",
      "Epoch 2500, Loss: 0.20072364807128906\n",
      "Epoch 3000, Loss: 0.23898065090179443\n",
      "Epoch 3500, Loss: 0.21217553317546844\n",
      "Epoch 4000, Loss: 0.1772100180387497\n",
      "Epoch 4500, Loss: 0.16995103657245636\n",
      "Epoch 5000, Loss: 0.15249080955982208\n",
      "Epoch 5500, Loss: 0.15438060462474823\n",
      "Epoch 6000, Loss: 0.1668483167886734\n",
      "Epoch 6500, Loss: 0.1331923007965088\n",
      "Epoch 7000, Loss: 0.2237211912870407\n",
      "Epoch 7500, Loss: 0.1400073766708374\n",
      "Epoch 8000, Loss: 0.14664529263973236\n",
      "Epoch 8500, Loss: 0.16639156639575958\n",
      "Epoch 9000, Loss: 0.1977452039718628\n",
      "Epoch 9500, Loss: 0.1252157986164093\n",
      "Epoch 10000, Loss: 0.12161954492330551\n",
      "Epoch 10500, Loss: 0.20624598860740662\n",
      "Epoch 11000, Loss: 0.14733660221099854\n",
      "Epoch 11500, Loss: 0.16684341430664062\n",
      "Epoch 12000, Loss: 0.12096329778432846\n",
      "Epoch 12500, Loss: 0.10625214874744415\n",
      "Epoch 13000, Loss: 0.11592638492584229\n",
      "Epoch 13500, Loss: 0.11813338100910187\n",
      "Epoch 14000, Loss: 0.13057443499565125\n",
      "Epoch 14500, Loss: 0.17057636380195618\n",
      "Epoch 15000, Loss: 0.1289028376340866\n",
      "Epoch 15500, Loss: 0.12209846079349518\n",
      "Epoch 16000, Loss: 0.0911119133234024\n",
      "Epoch 16500, Loss: 0.12865141034126282\n",
      "Epoch 17000, Loss: 0.11927638202905655\n",
      "Epoch 17500, Loss: 0.11130727827548981\n",
      "Epoch 18000, Loss: 0.10512850433588028\n",
      "Epoch 18500, Loss: 0.14948709309101105\n",
      "Epoch 19000, Loss: 0.14026689529418945\n",
      "Epoch 19500, Loss: 0.10069787502288818\n",
      "Epoch 20000, Loss: 0.10615833103656769\n",
      "Epoch 20500, Loss: 0.09178738296031952\n",
      "Epoch 21000, Loss: 0.09927302598953247\n",
      "Epoch 21500, Loss: 0.11407999694347382\n",
      "Epoch 22000, Loss: 0.13662099838256836\n",
      "Epoch 22500, Loss: 0.07918006926774979\n",
      "Epoch 23000, Loss: 0.09347754716873169\n",
      "Epoch 23500, Loss: 0.10270147025585175\n",
      "Epoch 24000, Loss: 0.11654782295227051\n",
      "Epoch 24500, Loss: 0.08340690284967422\n",
      "Epoch 25000, Loss: 0.1084207072854042\n",
      "Epoch 25500, Loss: 0.10392417758703232\n",
      "Epoch 26000, Loss: 0.1551559865474701\n",
      "Epoch 26500, Loss: 0.09803149104118347\n",
      "Epoch 27000, Loss: 0.10543979704380035\n",
      "Epoch 27500, Loss: 0.08742158859968185\n",
      "Epoch 28000, Loss: 0.10653641074895859\n",
      "Epoch 28500, Loss: 0.1211705207824707\n",
      "Epoch 29000, Loss: 0.09896794706583023\n",
      "Epoch 29500, Loss: 0.08716428279876709\n",
      "Epoch 30000, Loss: 0.07586578279733658\n",
      "Epoch 30500, Loss: 0.09974946081638336\n",
      "Epoch 31000, Loss: 0.14194539189338684\n",
      "Epoch 31500, Loss: 0.09738776832818985\n",
      "Epoch 32000, Loss: 0.08912762999534607\n",
      "Epoch 32500, Loss: 0.1128317341208458\n",
      "Epoch 33000, Loss: 0.10290367901325226\n",
      "Epoch 33500, Loss: 0.07411853224039078\n",
      "Epoch 34000, Loss: 0.13649049401283264\n",
      "Epoch 34500, Loss: 0.06995093822479248\n",
      "Epoch 35000, Loss: 0.13370779156684875\n",
      "Epoch 35500, Loss: 0.08162956684827805\n",
      "Epoch 36000, Loss: 0.09534674137830734\n",
      "Epoch 36500, Loss: 0.05676526576280594\n",
      "Epoch 37000, Loss: 0.07622507959604263\n",
      "Epoch 37500, Loss: 0.0851999968290329\n",
      "Epoch 38000, Loss: 0.09263062477111816\n",
      "Epoch 38500, Loss: 0.10560288280248642\n",
      "Epoch 39000, Loss: 0.08498289436101913\n",
      "Epoch 39500, Loss: 0.11210600286722183\n",
      "Epoch 40000, Loss: 0.07939083874225616\n",
      "Epoch 40500, Loss: 0.0650746151804924\n",
      "Epoch 41000, Loss: 0.08343923836946487\n",
      "Epoch 41500, Loss: 0.0759136825799942\n",
      "Epoch 42000, Loss: 0.1425820142030716\n",
      "Epoch 42500, Loss: 0.08346651494503021\n",
      "Epoch 43000, Loss: 0.07803903520107269\n",
      "Epoch 43500, Loss: 0.045155320316553116\n",
      "Epoch 44000, Loss: 0.07712089270353317\n",
      "Epoch 44500, Loss: 0.060002438724040985\n",
      "Epoch 45000, Loss: 0.0627458244562149\n",
      "Epoch 45500, Loss: 0.0747673511505127\n",
      "Epoch 46000, Loss: 0.07930239289999008\n",
      "Epoch 46500, Loss: 0.08867917209863663\n",
      "Epoch 47000, Loss: 0.08068601042032242\n",
      "Epoch 47500, Loss: 0.05168118327856064\n",
      "Epoch 48000, Loss: 0.05874742195010185\n",
      "Epoch 48500, Loss: 0.04865802451968193\n",
      "Epoch 49000, Loss: 0.0555531270802021\n",
      "Epoch 49500, Loss: 0.04573860391974449\n",
      "Epoch 50000, Loss: 0.04277818650007248\n",
      "Epoch 50500, Loss: 0.07832495868206024\n",
      "Epoch 51000, Loss: 0.06791897863149643\n",
      "Epoch 51500, Loss: 0.05516818165779114\n",
      "Epoch 52000, Loss: 0.03300526365637779\n",
      "Epoch 52500, Loss: 0.05343049019575119\n",
      "Epoch 53000, Loss: 0.08308722823858261\n",
      "Epoch 53500, Loss: 0.02920231781899929\n",
      "Epoch 54000, Loss: 0.0572945661842823\n",
      "Epoch 54500, Loss: 0.05372599512338638\n",
      "Epoch 55000, Loss: 0.07556760311126709\n",
      "Epoch 55500, Loss: 0.049263857305049896\n",
      "Epoch 56000, Loss: 0.05651802942156792\n",
      "Epoch 56500, Loss: 0.04386419057846069\n",
      "Epoch 57000, Loss: 0.0636623352766037\n",
      "Epoch 57500, Loss: 0.10829181969165802\n",
      "Epoch 58000, Loss: 0.06480946391820908\n",
      "Epoch 58500, Loss: 0.04720175266265869\n",
      "Epoch 59000, Loss: 0.04847903549671173\n",
      "Epoch 59500, Loss: 0.03542153909802437\n",
      "Epoch 60000, Loss: 0.0868292823433876\n",
      "Epoch 60500, Loss: 0.10349059104919434\n",
      "Epoch 61000, Loss: 0.0782557800412178\n",
      "Epoch 61500, Loss: 0.09120362251996994\n",
      "Epoch 62000, Loss: 0.027545809745788574\n",
      "Epoch 62500, Loss: 0.07009609043598175\n",
      "Epoch 63000, Loss: 0.05479971691966057\n",
      "Epoch 63500, Loss: 0.025158260017633438\n",
      "Epoch 64000, Loss: 0.04285498708486557\n",
      "Epoch 64500, Loss: 0.055304378271102905\n",
      "Epoch 65000, Loss: 0.0703718513250351\n",
      "Epoch 65500, Loss: 0.10385762155056\n",
      "Epoch 66000, Loss: 0.0484306626021862\n",
      "Epoch 66500, Loss: 0.05734606832265854\n",
      "Epoch 67000, Loss: 0.05207318812608719\n",
      "Epoch 67500, Loss: 0.07658199965953827\n",
      "Epoch 68000, Loss: 0.060117948800325394\n",
      "Epoch 68500, Loss: 0.029138237237930298\n",
      "Epoch 69000, Loss: 0.0407077856361866\n",
      "Epoch 69500, Loss: 0.03517996519804001\n",
      "Epoch 70000, Loss: 0.07145767658948898\n",
      "Epoch 70500, Loss: 0.07782750576734543\n",
      "Epoch 71000, Loss: 0.04267919063568115\n",
      "Epoch 71500, Loss: 0.07080065459012985\n",
      "Epoch 72000, Loss: 0.0666237473487854\n",
      "Epoch 72500, Loss: 0.058063436299562454\n",
      "Epoch 73000, Loss: 0.07297825068235397\n",
      "Epoch 73500, Loss: 0.03667356073856354\n",
      "Epoch 74000, Loss: 0.029186367988586426\n",
      "Epoch 74500, Loss: 0.04109826683998108\n",
      "Epoch 75000, Loss: 0.041254207491874695\n",
      "Epoch 75500, Loss: 0.024615740403532982\n",
      "Epoch 76000, Loss: 0.031628675758838654\n",
      "Epoch 76500, Loss: 0.0715578943490982\n",
      "Epoch 77000, Loss: 0.04488622769713402\n",
      "Epoch 77500, Loss: 0.1157621517777443\n",
      "Epoch 78000, Loss: 0.049394939094781876\n",
      "Epoch 78500, Loss: 0.03261064365506172\n",
      "Epoch 79000, Loss: 0.031177619472146034\n",
      "Epoch 79500, Loss: 0.05997403338551521\n",
      "Epoch 80000, Loss: 0.058390937745571136\n",
      "Epoch 80500, Loss: 0.06893948465585709\n",
      "Epoch 81000, Loss: 0.051516640931367874\n",
      "Epoch 81500, Loss: 0.04478064179420471\n",
      "Epoch 82000, Loss: 0.036067575216293335\n",
      "Epoch 82500, Loss: 0.06727655231952667\n",
      "Epoch 83000, Loss: 0.028475109487771988\n",
      "Epoch 83500, Loss: 0.04296834021806717\n",
      "Epoch 84000, Loss: 0.04134526476264\n",
      "Epoch 84500, Loss: 0.03314539045095444\n",
      "Epoch 85000, Loss: 0.039045680314302444\n",
      "Epoch 85500, Loss: 0.03353319317102432\n",
      "Epoch 86000, Loss: 0.04756752401590347\n",
      "Epoch 86500, Loss: 0.024614866822957993\n",
      "Epoch 87000, Loss: 0.05295667052268982\n",
      "Epoch 87500, Loss: 0.06872089207172394\n",
      "Epoch 88000, Loss: 0.0769866332411766\n",
      "Epoch 88500, Loss: 0.03540816158056259\n",
      "Epoch 89000, Loss: 0.0489765927195549\n",
      "Epoch 89500, Loss: 0.12061639875173569\n",
      "Epoch 90000, Loss: 0.07477623224258423\n",
      "Epoch 90500, Loss: 0.023096689954400063\n",
      "Epoch 91000, Loss: 0.046926382929086685\n",
      "Epoch 91500, Loss: 0.07996256649494171\n",
      "Epoch 92000, Loss: 0.04048704355955124\n",
      "Epoch 92500, Loss: 0.06331391632556915\n",
      "Epoch 93000, Loss: 0.06678939610719681\n",
      "Epoch 93500, Loss: 0.05266866832971573\n",
      "Epoch 94000, Loss: 0.04897961765527725\n",
      "Epoch 94500, Loss: 0.025443902239203453\n",
      "Epoch 95000, Loss: 0.04862350970506668\n",
      "Epoch 95500, Loss: 0.057361334562301636\n",
      "Epoch 96000, Loss: 0.036736730486154556\n",
      "Epoch 96500, Loss: 0.08868969231843948\n",
      "Epoch 97000, Loss: 0.03833160549402237\n",
      "Epoch 97500, Loss: 0.029025431722402573\n",
      "Epoch 98000, Loss: 0.04503398388624191\n",
      "Epoch 98500, Loss: 0.04914582520723343\n",
      "Epoch 99000, Loss: 0.028410542756319046\n",
      "Epoch 99500, Loss: 0.04430631175637245\n",
      "Epoch 99999, Loss: 0.03696921840310097\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 100000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 500 == 0 or epoch == epochs-1:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f38a0b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Relative Error: 0.044689537286758424\n"
     ]
    }
   ],
   "source": [
    "# Calculate L2 relative error\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(x_test)\n",
    "    l2_norm = torch.sqrt(torch.sum((y_pred_test - y_test) ** 2))\n",
    "    f_norm = torch.sqrt(torch.sum(y_test ** 2))\n",
    "    l2_relative_error = l2_norm / f_norm\n",
    "    print(f'L2 Relative Error: {l2_relative_error.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028a8ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
