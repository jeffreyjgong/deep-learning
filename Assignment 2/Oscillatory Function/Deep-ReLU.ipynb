{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7ea524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "254228d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return jnp.where(x < 0, 5 + jnp.sum(jnp.sin(jnp.arange(1,5) * x[:, None]), axis=1), jnp.cos(10*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5b488a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_train=200, n_test=500):\n",
    "    xs_train = jnp.linspace(-jnp.pi, jnp.pi, n_train)\n",
    "    ys_train = f(xs_train)\n",
    "    xs_test = jnp.linspace(-jnp.pi, jnp.pi, n_test)\n",
    "    ys_test = f(xs_test)\n",
    "    return xs_train, ys_train, xs_test, ys_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90177a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return jnp.maximum(0, x)\n",
    "\n",
    "def init_network_params(layer_widths, key):\n",
    "    params = []\n",
    "    keys = random.split(key, len(layer_widths))\n",
    "    for i, (m, n) in enumerate(zip(layer_widths[:-1], layer_widths[1:])):\n",
    "        key, subkey = random.split(keys[i])\n",
    "        params.append((random.normal(key, (n, m)) * jnp.sqrt(2/m), random.normal(subkey, (n, 1)) * jnp.sqrt(2/m)))\n",
    "    return params\n",
    "\n",
    "def predict(params, x):\n",
    "    # Ensure x is a 2D array with each input as a row\n",
    "    x = x.reshape(-1, 1) if x.ndim == 1 else x\n",
    "\n",
    "    activations = x\n",
    "    # Apply computations for the first hidden layer\n",
    "    for w, b in params[:-2]:  # Iterate through all but the last layer\n",
    "        activations = jnp.dot(activations, w.T) + b.reshape(-1)\n",
    "        activations = relu(activations)\n",
    "\n",
    "    # Apply computations for the last layer (output layer)\n",
    "    final_w, final_b = params[-1]\n",
    "    y_pred = jnp.dot(activations, final_w.T) + final_b.reshape(-1)\n",
    "\n",
    "    return y_pred.flatten() if x.shape[1] == 1 else y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fb09db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(params, xs, ys):\n",
    "    preds = predict(params, xs)\n",
    "    return jnp.mean((preds - ys)**2)\n",
    "\n",
    "@jit\n",
    "def update(params, xs, ys, lr=0.01):\n",
    "    grads = grad(mse_loss)(params, xs, ys)\n",
    "    return [(w - lr * dw, b - lr*db) for (w, b), (dw, db) in zip(params, grads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f95e488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_relative_error(params, xs, ys):\n",
    "    preds = predict(params, xs)\n",
    "    return jnp.sqrt(jnp.sum((preds-ys) ** 2)) / jnp.sqrt(jnp.sum(ys ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50cada5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m         std_error \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(errors[width])\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWidth: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwidth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Mean L^2 Relative Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_error\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Std Dev: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstd_error\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m run_experiment(widths\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m1000\u001b[39m])\n",
      "Cell \u001b[0;32mIn[12], line 18\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(widths, n_train, n_test, n_epochs, lr, n_runs)\u001b[0m\n\u001b[1;32m     16\u001b[0m layer_widths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, width, width, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# input layer, 2 hidden layers, output layer\u001b[39;00m\n\u001b[1;32m     17\u001b[0m params \u001b[38;5;241m=\u001b[39m init_network_params(layer_widths, key)\n\u001b[0;32m---> 18\u001b[0m params \u001b[38;5;241m=\u001b[39m train_network(params, xs_train, ys_train, n_epochs, lr)\n\u001b[1;32m     19\u001b[0m error \u001b[38;5;241m=\u001b[39m test_network(params, xs_test, ys_test)\n\u001b[1;32m     20\u001b[0m errors[width]\u001b[38;5;241m.\u001b[39mappend(error)\n",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(params, xs, ys, n_epochs, lr)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_network\u001b[39m(params, xs, ys, n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m----> 3\u001b[0m         params \u001b[38;5;241m=\u001b[39m update(params, xs, ys, lr)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m params\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_network(params, xs, ys, n_epochs=1000, lr=0.01):\n",
    "    for epoch in range(n_epochs):\n",
    "        params = update(params, xs, ys, lr)\n",
    "    return params\n",
    "\n",
    "def test_network(params, xs_test, ys_test):\n",
    "    return l2_relative_error(params, xs_test, ys_test)\n",
    "\n",
    "def run_experiment(widths, n_train=200, n_test=500, n_epochs=20000, lr=0.0005, n_runs=3):\n",
    "    xs_train, ys_train, xs_test, ys_test = generate_data(n_train, n_test)\n",
    "    errors = {width: [] for width in widths}\n",
    "    \n",
    "    for width in widths:\n",
    "        for run in range(n_runs):\n",
    "            key = random.PRNGKey(run)\n",
    "            layer_widths = [1, width, width, 1] # input layer, 2 hidden layers, output layer\n",
    "            params = init_network_params(layer_widths, key)\n",
    "            params = train_network(params, xs_train, ys_train, n_epochs, lr)\n",
    "            error = test_network(params, xs_test, ys_test)\n",
    "            errors[width].append(error)\n",
    "    \n",
    "    for width in widths:\n",
    "        mean_error = np.mean(errors[width])\n",
    "        std_error = np.std(errors[width])\n",
    "        print(f\"Width: {width}, Mean L^2 Relative Error: {mean_error}, Std Dev: {std_error}\")\n",
    "\n",
    "run_experiment(widths=[10, 30, 100, 300, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe74beb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb11703d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
